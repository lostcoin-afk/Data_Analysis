{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1168, 83), (292, 83), (1168,), (292,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"X_train1.csv\")#Feature Engineered dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.drop(columns=['SalePrice']), dataset['SalePrice'], test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1168 entries, 254 to 1126\n",
      "Data columns (total 83 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Id               1168 non-null   int64  \n",
      " 1   MSSubClass       1168 non-null   float64\n",
      " 2   MSZoning         1168 non-null   float64\n",
      " 3   LotFrontage      1168 non-null   float64\n",
      " 4   LotArea          1168 non-null   float64\n",
      " 5   Street           1168 non-null   float64\n",
      " 6   Alley            1168 non-null   float64\n",
      " 7   LotShape         1168 non-null   float64\n",
      " 8   LandContour      1168 non-null   float64\n",
      " 9   Utilities        1168 non-null   float64\n",
      " 10  LotConfig        1168 non-null   float64\n",
      " 11  LandSlope        1168 non-null   float64\n",
      " 12  Neighborhood     1168 non-null   float64\n",
      " 13  Condition1       1168 non-null   float64\n",
      " 14  Condition2       1168 non-null   float64\n",
      " 15  BldgType         1168 non-null   float64\n",
      " 16  HouseStyle       1168 non-null   float64\n",
      " 17  OverallQual      1168 non-null   float64\n",
      " 18  OverallCond      1168 non-null   float64\n",
      " 19  YearBuilt        1168 non-null   float64\n",
      " 20  YearRemodAdd     1168 non-null   float64\n",
      " 21  RoofStyle        1168 non-null   float64\n",
      " 22  RoofMatl         1168 non-null   float64\n",
      " 23  Exterior1st      1168 non-null   float64\n",
      " 24  Exterior2nd      1168 non-null   float64\n",
      " 25  MasVnrType       1168 non-null   float64\n",
      " 26  MasVnrArea       1168 non-null   float64\n",
      " 27  ExterQual        1168 non-null   float64\n",
      " 28  ExterCond        1168 non-null   float64\n",
      " 29  Foundation       1168 non-null   float64\n",
      " 30  BsmtQual         1168 non-null   float64\n",
      " 31  BsmtCond         1168 non-null   float64\n",
      " 32  BsmtExposure     1168 non-null   float64\n",
      " 33  BsmtFinType1     1168 non-null   float64\n",
      " 34  BsmtFinSF1       1168 non-null   float64\n",
      " 35  BsmtFinType2     1168 non-null   float64\n",
      " 36  BsmtFinSF2       1168 non-null   float64\n",
      " 37  BsmtUnfSF        1168 non-null   float64\n",
      " 38  TotalBsmtSF      1168 non-null   float64\n",
      " 39  Heating          1168 non-null   float64\n",
      " 40  HeatingQC        1168 non-null   float64\n",
      " 41  CentralAir       1168 non-null   float64\n",
      " 42  Electrical       1168 non-null   float64\n",
      " 43  1stFlrSF         1168 non-null   float64\n",
      " 44  2ndFlrSF         1168 non-null   float64\n",
      " 45  LowQualFinSF     1168 non-null   float64\n",
      " 46  GrLivArea        1168 non-null   float64\n",
      " 47  BsmtFullBath     1168 non-null   float64\n",
      " 48  BsmtHalfBath     1168 non-null   float64\n",
      " 49  FullBath         1168 non-null   float64\n",
      " 50  HalfBath         1168 non-null   float64\n",
      " 51  BedroomAbvGr     1168 non-null   float64\n",
      " 52  KitchenAbvGr     1168 non-null   float64\n",
      " 53  KitchenQual      1168 non-null   float64\n",
      " 54  TotRmsAbvGrd     1168 non-null   float64\n",
      " 55  Functional       1168 non-null   float64\n",
      " 56  Fireplaces       1168 non-null   float64\n",
      " 57  FireplaceQu      1168 non-null   float64\n",
      " 58  GarageType       1168 non-null   float64\n",
      " 59  GarageYrBlt      1168 non-null   float64\n",
      " 60  GarageFinish     1168 non-null   float64\n",
      " 61  GarageCars       1168 non-null   float64\n",
      " 62  GarageArea       1168 non-null   float64\n",
      " 63  GarageQual       1168 non-null   float64\n",
      " 64  GarageCond       1168 non-null   float64\n",
      " 65  PavedDrive       1168 non-null   float64\n",
      " 66  WoodDeckSF       1168 non-null   float64\n",
      " 67  OpenPorchSF      1168 non-null   float64\n",
      " 68  EnclosedPorch    1168 non-null   float64\n",
      " 69  3SsnPorch        1168 non-null   float64\n",
      " 70  ScreenPorch      1168 non-null   float64\n",
      " 71  PoolArea         1168 non-null   float64\n",
      " 72  PoolQC           1168 non-null   float64\n",
      " 73  Fence            1168 non-null   float64\n",
      " 74  MiscFeature      1168 non-null   float64\n",
      " 75  MiscVal          1168 non-null   float64\n",
      " 76  MoSold           1168 non-null   float64\n",
      " 77  YrSold           1168 non-null   float64\n",
      " 78  SaleType         1168 non-null   float64\n",
      " 79  SaleCondition    1168 non-null   float64\n",
      " 80  LotFrontage_NaN  1168 non-null   float64\n",
      " 81  MasVnrArea_NaN   1168 non-null   float64\n",
      " 82  GarageYrBlt_NaN  1168 non-null   float64\n",
      "dtypes: float64(82), int64(1)\n",
      "memory usage: 766.5 KB\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index: 1168 entries, 254 to 1126\n",
      "Series name: SalePrice\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "1168 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 18.2 KB\n"
     ]
    }
   ],
   "source": [
    "# y_train = dataset[['SalePrice']]\n",
    "# y_train.info()\n",
    "X_train.head()\n",
    "X_train.info()\n",
    "y_train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = dataset.drop(['Id','SalePrice'], axis=1)\n",
    "# Remove 'Id' column from the already split X_train\n",
    "X_train = X_train.drop(columns=['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features before selection: 82\n",
      "Total features after selection: 12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Initialize the feature selection model using Lasso\n",
    "feature_sel_model = SelectFromModel(Lasso(alpha=0.01, random_state=42))\n",
    "\n",
    "# Fit the model on X_train and y_train\n",
    "feature_sel_model.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X_train.columns[feature_sel_model.get_support()]\n",
    "\n",
    "# Apply the same feature selection to X_test\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Print number of selected features\n",
    "print(f\"Total features before selection: {X_train.shape[1]}\")\n",
    "print(f\"Total features after selection: {len(selected_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "        True,  True, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "       False, False,  True,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_sel_model.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # let's print the number of total and selected features\n",
    "\n",
    "# # # this is how we can make a list of the selected features\n",
    "# # selected_feat = X_train.columns[(feature_sel_model.get_support())]\n",
    "\n",
    "# # # let's print some stats\n",
    "# # print('total features: {}'.format((X_train.shape[1])))\n",
    "# # print('selected features: {}'.format(len(selected_feat)))\n",
    "# # print('features with coefficients shrank to zero: {}'.format(\n",
    "# #     np.sum(feature_sel_model.estimator_.coef_ == 0)))\n",
    "\n",
    "\n",
    "# # Apply feature selection\n",
    "# feature_sel_model = SelectFromModel(Lasso(alpha=0.005, random_state=42))\n",
    "# feature_sel_model.fit(X_train, y_train)\n",
    "\n",
    "# # Extract selected features\n",
    "# selected_feat = X_train.columns[feature_sel_model.get_support()]\n",
    "\n",
    "# # Apply feature selection to X_test\n",
    "# X_train_selected = X_train[selected_feat]\n",
    "# X_test_selected = X_test[selected_feat]\n",
    "\n",
    "# # Print feature selection stats\n",
    "# print('Total features before selection:', X_train.shape[1])\n",
    "# print('Selected features:', len(selected_feat))\n",
    "# print('Features with coefficients shrank to zero:', np.sum(feature_sel_model.estimator_.coef_ == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OverallQual', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
       "       'CentralAir', 'GrLivArea', 'FullBath', 'Fireplaces', 'GarageCars',\n",
       "       'WoodDeckSF', 'OpenPorchSF'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254     11.884489\n",
       "1066    12.089539\n",
       "638     11.350407\n",
       "799     12.072541\n",
       "380     11.751942\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 10.643876398907027\n",
      "Coefficients: [ 0.8268959  -0.18214685 -0.13195094 -0.02513471  0.15990865  0.10076548\n",
      "  1.14258727 -0.02674805  0.16542853  0.36275267  0.03721724  0.0324454 ]\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train_selected, y_train)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"Coefficients:\", model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linear_regression_model.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, \"linear_regression_model.pkl\")  # Save model as a .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = joblib.load(\"linear_regression_model.pkl\")  # Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted SalePrice : [11.89445091 12.63559282 11.60642459 12.10631521 12.61861209 11.30948045\n",
      " 12.35788879 12.08388147 11.26872641 11.66597954 11.86246124 11.62456408\n",
      " 11.43295911 12.11090695 12.15081173 11.75375439 12.26351474 11.78788823\n",
      " 11.6183508  12.25600429 12.06497275 12.24890138 12.14911189 11.67049244\n",
      " 12.20194535 12.01295243 12.17786103 11.50933276 12.09176446 12.16079008\n",
      " 11.73496238 12.52928554 12.08206813 11.49602456 12.46813229 11.89833037\n",
      " 11.90576237 12.30600886 12.68799373 11.47473839 11.80310121 12.46922688\n",
      " 11.65397349 12.4791371  11.72512227 11.81288181 11.61061385 11.6500538\n",
      " 12.87539102 11.78491366 11.62426375 12.22841525 11.78566183 12.55624859\n",
      " 11.97414428 12.35035954 12.335605   11.8639663  11.99383891 11.58466294\n",
      " 10.99834745 11.81512184 12.57490073 12.36777115 12.48779028 12.26554026\n",
      " 11.50990878 12.68796642 11.65103431 12.14986752 11.84023227 11.80756828\n",
      " 11.48341183 11.30747906 12.81879012 12.15205972 12.63716716 12.56290435\n",
      " 11.67929425 11.60688347 11.82606661 11.48101391 11.58655839 11.55896304\n",
      " 12.04763897 11.65185522 12.5064619  12.25337401 11.98114917 12.1598655\n",
      " 11.94009159 11.95856808 11.66132705 12.42816148 11.47918044 12.11762305\n",
      " 11.93856664 12.19568305 12.1699086  12.40603694 12.1244507  12.2859294\n",
      " 12.40931848 11.82618686 12.05614266 12.08262366 11.98213373 12.42571907\n",
      " 11.85058524 12.18243616 10.95805672 11.60035532 11.78619971 11.75258185\n",
      " 12.23476369 11.67121054 11.46470603 11.68641633 12.0081266  12.48183019\n",
      " 11.87513447 11.97383089 12.11782815 12.04210072 12.11375049 11.64791155\n",
      " 12.45624178 11.45356539 11.73845903 12.22559524 12.26127714 12.69820188\n",
      " 12.19566352 11.77737591 10.87407552 12.74804579 12.64317691 11.69027809\n",
      " 12.3684836  13.09713706 12.67157086 11.71578943 12.08079966 12.03832138\n",
      " 11.68362996 11.74141427 12.18053002 12.09337184 11.66440749 11.07101373\n",
      " 11.48792323 12.05914462 12.32166216 12.01337498 11.28156222 11.74049679\n",
      " 11.81304819 11.89320498 11.27081419 11.82668174 12.14804217 11.97954137\n",
      " 12.55701453 11.96997202 11.70408441 11.56395431 12.35096073 12.56969779\n",
      " 12.8211439  12.11832008 12.8403403  11.27597722 11.53230516 12.10919662\n",
      " 12.59664811 11.77132285 11.89095915 12.32708924 11.72226505 12.12132357\n",
      " 11.98911351 11.49473719 11.77037873 11.99688446 12.52081488 11.94910077\n",
      " 12.60141795 12.42560814 12.16711927 11.49009972 11.92420597 11.52325544\n",
      " 11.8243444  11.91983481 12.17306104 12.00714743 12.35012743 11.38736703\n",
      " 12.36191435 11.64920322 12.30016205 12.28621655 11.80406719 12.66417357\n",
      " 12.20051917 11.67037479 12.47688183 11.8094542  12.08974139 11.58853466\n",
      " 12.51165623 11.93560341 11.56210529 12.08884037 12.24707606 12.39256914\n",
      " 12.28193855 11.76674121 11.76267531 11.88072904 11.82976437 12.36225686\n",
      " 12.03802726 11.5404215  12.37951699 11.87030469 11.50727637 11.46850247\n",
      " 12.10772953 11.41194384 11.47335591 12.19010546 11.67732605 11.62627013\n",
      " 12.48841193 11.7860037  12.18401294 11.95681263 12.38937085 11.8302583\n",
      " 11.63294662 12.3801911  12.30644915 12.79223578 12.16657847 11.7048729\n",
      " 11.95904199 12.04492102 11.92583575 11.46974723 12.11140671 12.12714991\n",
      " 11.81936191 11.30737712 11.80959501 11.96068447 11.85692895 11.77016676\n",
      " 12.14031579 12.48511959 12.49145741 12.07547461 11.65277826 12.28382793\n",
      " 12.48628873 12.29456881 12.09215514 11.91477097 11.55694638 12.25212923\n",
      " 12.85831737 12.31611758 12.39481885 11.7337298  11.60546077 11.75457208\n",
      " 12.16965109 12.4743166  12.04278624 11.83249407 12.26093431 11.39065782\n",
      " 12.15962751 11.50245697 12.5676076  11.93674632 12.3114554  11.72720728\n",
      " 12.33847031 12.3077728  11.62672694 11.58792833]\n",
      "Predicted SalePrice (Original Scale): [146451.69212479 307304.01832703 109800.96409182 181011.38464714\n",
      " 302129.82696479  81591.50691418 232789.24306812 176995.83295802\n",
      "  78333.16936338 116538.79987152 141840.89380491 111810.87154851\n",
      "  92314.74070162 181844.45431363 189247.64630924 127230.33514321\n",
      " 211824.78808976 131648.1656834  111118.31314835 210239.84761056\n",
      " 173680.51116189 208751.82311538 188926.22739031 117065.91566366\n",
      " 199176.2419173  164876.57329802 194436.52265584  99641.37381087\n",
      " 178396.60287307 191145.47777717 124861.74727951 276311.88866881\n",
      " 176675.17126008  98324.11127068 259920.81055741 147020.94900003\n",
      " 148117.68017404 221020.08486426 323836.39909409  96253.28599407\n",
      " 133666.23779674 260205.47249507 115147.99442174 262796.98669664\n",
      " 123639.11883871 134979.98866332 110261.91416092 114697.5339135\n",
      " 390581.14164292 131257.15086262 111777.29712019 204518.81323\n",
      " 131355.38965694 283863.44851351 158600.58517745 231043.09728712\n",
      " 227659.1881899  142054.53332747 161755.12783922 107437.32572295\n",
      "  59775.27861395 135282.68643068 289207.79597801 235101.15471712\n",
      " 265080.88244551 212254.27775642  99698.7861805  323827.55656807\n",
      " 114810.05129718 189069.0402658  138722.7023663  134264.66942734\n",
      "  97091.76349208  81428.37358542 369087.90454072 189483.97185859\n",
      " 307788.19876738 285759.07861443 118100.85593856 109851.36176456\n",
      " 136771.45578342  96859.22500648 107641.16042287 104711.37505528\n",
      " 170695.91392828 114904.33787283 270076.87055482 209687.58436756\n",
      " 159715.46512256 190968.82944216 153290.72904517 156149.33097412\n",
      " 115997.86284139 249736.45861436  96681.79920468 183069.84921203\n",
      " 153057.14659974 197932.83822881 192896.41265545 244271.83030329\n",
      " 184324.06293651 216626.38137975 245074.73400475 136787.90384146\n",
      " 172153.64881396 176773.34655761 159872.79200688 249127.2451744\n",
      " 140166.35428411 195328.13372326  57414.76142726 109136.57124167\n",
      " 131426.06311276 127081.24088534 205821.31906337 117150.01102691\n",
      "  95292.46583756 118944.98232005 164082.82280574 263505.67790431\n",
      " 143649.91493651 158550.88888713 183107.40158257 169753.17069019\n",
      " 182362.27124386 114452.08578907 256848.52060094  94236.73809426\n",
      " 125299.10903161 203942.88062222 211351.33916559 327159.1000209\n",
      " 197928.97193473 130271.48682514  52789.91881128 343879.22727116\n",
      " 309643.498483   119405.20701068 235268.71413739 487544.60210785\n",
      " 318561.51118129 122490.58241415 176451.20498239 169112.82666076\n",
      " 118614.01813111 125669.9460023  194956.16539381 178683.58455755\n",
      " 116355.738426    64280.63720006  97530.77315109 172671.22376328\n",
      " 224506.99945756 164946.25688702  79345.1193803  125554.69843595\n",
      " 135002.44847704 146269.33804756  78496.88270398 136855.61443396\n",
      " 188724.23857854 159458.88185246 284080.95567494 157940.24184874\n",
      " 121065.18684646 105235.32460088 231182.03938009 287706.97287608\n",
      " 369957.68058661 183197.49898689 377128.13822236  78903.21258823\n",
      " 101956.87051322 181533.7049958  295566.19828588 129485.3273125\n",
      " 145941.21082294 225728.72880425 123286.35927712 183748.55724959\n",
      " 160992.57239542  98197.61307952 129363.13487074 162248.51218501\n",
      " 273981.2304018  154677.99263866 296979.37024258 249099.61202616\n",
      " 192359.11063079  97743.27894774 150874.85087601 101038.35107832\n",
      " 136536.11056176 150216.79204922 193505.46587458 163922.23678298\n",
      " 230989.47493203  88200.42225418 233728.2404268  114600.01516154\n",
      " 219731.59432267 216688.59290869 133795.4189033  316213.71197537\n",
      " 198892.38399729 117052.14427003 262204.97670103 134518.12181829\n",
      " 178036.05858555 107854.09888571 271483.3881775  152604.27509614\n",
      " 105040.92214461 177875.71818409 208371.1317683  241004.07982127\n",
      " 215763.58043902 128893.42898554 128370.42534307 144455.82640797\n",
      " 137278.14060671 233808.30821774 169063.09437073 102787.75418577\n",
      " 237878.89672124 142957.79041088  99436.68333796  95654.92564313\n",
      " 181267.57373821  90394.96436029  96120.30914253 196831.92278053\n",
      " 117868.63887111 112001.78953243 265245.72196989 131400.30479817\n",
      " 195636.36536595 155875.45889415 240234.51072674 137345.9636464\n",
      " 112752.07078339 238039.30755819 221117.41959868 359416.00339511\n",
      " 192255.10975442 121160.68231386 156223.3498592  170232.60014816\n",
      " 151120.94430205  95774.06673494 181935.35563626 184822.26373291\n",
      " 135857.51200821  81420.07331292 134537.06364248 156480.1537437\n",
      " 141058.35504995 129335.71664069 187271.70198469 264373.87974489\n",
      " 266054.75475142 175514.09133132 115010.44845078 216171.62382373\n",
      " 264683.15022504 218506.01245486 178466.31390741 149458.04152573\n",
      " 104500.42146992 209426.73207641 383969.10249591 223265.64525815\n",
      " 241546.87807304 124707.94020334 109695.18688583 127334.41367205\n",
      " 192846.74563806 261533.2219807  169869.57969618 137653.38121775\n",
      " 211278.89374083  88491.14930548 190923.38698074  98958.61052697\n",
      " 287106.23975046 152778.7880177  222227.16375651 123897.17618845\n",
      " 228312.43689644 221410.29639813 112052.96496008 107788.72352391]\n"
     ]
    }
   ],
   "source": [
    "# Assume 'new_data' is a DataFrame with the same feature columns as X_train\n",
    "predicted_price = model_loaded.predict(X_test_selected)\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# Apply inverse log transformation\n",
    "predicted_price_original = np.exp(predicted_price)\n",
    "print(f\"Predicted SalePrice : {predicted_price}\")\n",
    "print(f\"Predicted SalePrice (Original Scale): {predicted_price_original}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.13\n",
      "Mean Squared Error (MSE): 0.03\n",
      "Root Mean Squared Error (RMSE): 0.17\n",
      "R² Score: 0.8517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Apply inverse log transformation on predictions and actual values\n",
    "# y_test_original = np.exp(y_test)  # Convert test targets back to original scale\n",
    "# predicted_price_original = np.exp(predicted_price)  # Convert predictions back to original scale\n",
    "\n",
    "# Calculate performance metrics\n",
    "mae = mean_absolute_error(y_test, predicted_price)\n",
    "mse = mean_squared_error(y_test, predicted_price)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "r2 = r2_score(y_test, predicted_price)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
